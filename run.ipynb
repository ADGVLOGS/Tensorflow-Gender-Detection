{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Desktop Version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
    "from tensorflow.keras.models import load_model\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import os\r\n",
    "import cvlib as cv\r\n",
    "                    \r\n",
    "# load model\r\n",
    "model = load_model('gender_detection.model')\r\n",
    "\r\n",
    "# open webcam\r\n",
    "webcam = cv2.VideoCapture(0)\r\n",
    "    \r\n",
    "classes = ['Male','Female']\r\n",
    "\r\n",
    "# loop through frames\r\n",
    "while webcam.isOpened():\r\n",
    "\r\n",
    "    # read frame from webcam \r\n",
    "    status, frame = webcam.read(0)\r\n",
    "\r\n",
    "    # apply face detection\r\n",
    "    face, confidence = cv.detect_face(frame)\r\n",
    "\r\n",
    "\r\n",
    "    # loop through detected faces\r\n",
    "    for idx, f in enumerate(face):\r\n",
    "\r\n",
    "        # get corner points of face rectangle        \r\n",
    "        (startX, startY) = f[0], f[1]\r\n",
    "        (endX, endY) = f[2], f[3]\r\n",
    "\r\n",
    "        # draw rectangle over face\r\n",
    "        cv2.rectangle(frame, (startX,startY), (endX,endY), (0,255,0), 2)\r\n",
    "\r\n",
    "        # crop the detected face region\r\n",
    "        face_crop = np.copy(frame[startY:endY,startX:endX])\r\n",
    "\r\n",
    "        if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\r\n",
    "            continue\r\n",
    "\r\n",
    "        # preprocessing for gender detection model\r\n",
    "        face_crop = cv2.resize(face_crop, (96,96))\r\n",
    "        face_crop = face_crop.astype(\"float\") / 255.0\r\n",
    "        face_crop = img_to_array(face_crop)\r\n",
    "        face_crop = np.expand_dims(face_crop, axis=0)\r\n",
    "\r\n",
    "        # apply gender detection on face\r\n",
    "        conf = model.predict(face_crop)[0] # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\r\n",
    "\r\n",
    "        # get label with max accuracy\r\n",
    "        idx = np.argmax(conf)\r\n",
    "        label = classes[idx]\r\n",
    "\r\n",
    "        label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\r\n",
    "\r\n",
    "        Y = startY - 10 if startY - 10 > 10 else startY + 10\r\n",
    "\r\n",
    "        # write label and confidence above face rectangle\r\n",
    "        cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\r\n",
    "                    0.7, (0, 255, 0), 2)\r\n",
    "\r\n",
    "    # display output\r\n",
    "    cv2.imshow(\"ADG AI/ML GENDER DETECTOR\", frame)\r\n",
    "\r\n",
    "    # press \"Q\" to stop\r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break\r\n",
    "\r\n",
    "# release resources\r\n",
    "webcam.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Web Version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from flask import Flask, render_template, Response\r\n",
    "import cv2\r\n",
    "app = Flask(__name__)\r\n",
    "model = load_model('gender_detection.model')\r\n",
    "#camera = cv2.VideoCapture('rtsp://wowzaec2demo.streamlock.net/vod/mp4:BigBuckBunny_115k.mov')  # use 0 for web camera\r\n",
    "camera = cv2.VideoCapture(0)  # use 0 for web camera\r\n",
    "# for cctv camera use rtsp://username:password@ip_address:554/user=username_password='password'_channel=channel_number_stream=0.sdp' instead of camera\r\n",
    "# for local webcam use cv2.VideoCapture(0)\r\n",
    "\r\n",
    "def gen_frames():  # generate frame by frame from camera\r\n",
    "    while True:\r\n",
    "        # Capture frame-by-frame\r\n",
    "        success, frame = camera.read()  # read the camera frame\r\n",
    "     \r\n",
    "        # apply face detection\r\n",
    "        face, confidence = cv.detect_face(frame)\r\n",
    "\r\n",
    "        # loop through detected faces\r\n",
    "        for idx, f in enumerate(face):\r\n",
    "            # get corner points of face rectangle\r\n",
    "            (startX, startY) = f[0], f[1]\r\n",
    "            (endX, endY) = f[2], f[3]\r\n",
    "\r\n",
    "            # draw rectangle over face\r\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 255, 0), 2)\r\n",
    "\r\n",
    "            # crop the detected face region\r\n",
    "            face_crop = np.copy(frame[startY:endY, startX:endX])\r\n",
    "\r\n",
    "            if (face_crop.shape[0]) < 10 or (face_crop.shape[1]) < 10:\r\n",
    "                continue\r\n",
    "\r\n",
    "            # preprocessing for gender detection model\r\n",
    "            face_crop = cv2.resize(face_crop, (96, 96))\r\n",
    "            face_crop = face_crop.astype(\"float\") / 255.0\r\n",
    "            face_crop = img_to_array(face_crop)\r\n",
    "            face_crop = np.expand_dims(face_crop, axis=0)\r\n",
    "\r\n",
    "            # apply gender detection on face\r\n",
    "            # model.predict return a 2D matrix, ex: [[9.9993384e-01 7.4850512e-05]]\r\n",
    "            conf = model.predict(face_crop)[0]\r\n",
    "\r\n",
    "            # get label with max accuracy\r\n",
    "            idx = np.argmax(conf)\r\n",
    "            label = classes[idx]\r\n",
    "\r\n",
    "            label = \"{}: {:.2f}%\".format(label, conf[idx] * 100)\r\n",
    "\r\n",
    "            Y = startY - 10 if startY - 10 > 10 else startY + 10\r\n",
    "\r\n",
    "            # write label and confidence above face rectangle\r\n",
    "            cv2.putText(frame, label, (startX, Y),  cv2.FONT_HERSHEY_SIMPLEX,\r\n",
    "                        0.7, (0, 255, 0), 2)\r\n",
    "\r\n",
    "        if not success:\r\n",
    "            break\r\n",
    "        else:\r\n",
    "            \r\n",
    "            ret, buffer = cv2.imencode('.jpg', frame)\r\n",
    "            frame = buffer.tobytes()\r\n",
    "            yield (b'--frame\\r\\n'\r\n",
    "                    b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n')  # concat frame one by one and show result\r\n",
    "      \r\n",
    "\r\n",
    "@app.route('/video_feed')\r\n",
    "def video_feed():\r\n",
    "    #Video streaming route. Put this in the src attribute of an img tag\r\n",
    "    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')\r\n",
    "\r\n",
    "\r\n",
    "@app.route('/')\r\n",
    "def index():\r\n",
    "    return render_template('app.html')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "  app.run('localhost',8000)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " * Running on http://localhost:8000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [25/Aug/2021 00:49:11] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Aug/2021 00:49:11] \"GET /static/css/styles.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2021 00:49:12] \"GET /js/scripts.js HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [25/Aug/2021 00:49:12] \"GET /static/assets/img/plot.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Aug/2021 00:49:13] \"GET /video_feed HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Turns Off Camera in Web Version"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "camera.release()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}